---
title: "04_iCAR"
format: html
editor: visual
---



# 4. iCAR Anlysis {#4.0iCAR}

Run setup if starting a new environment.

```{r}

source("00_Setup.R")

#Manually Specify the start and end year of the analysis. These years should match those selected for the data cleaning scripts. 
Y1 = 2008
Y2 = 2024

#Load your saved species data 
sp.data<-read.csv("Data/sp.data.csv")
#Load your saved events data which is needed for zero-filling
events<-read.csv("Data/events.csv")

```

## 4.1 Spatial Data {#4.1iCAR}

Here the user will upload the desired spatial polygon for the analysis. We will use as our example the Watersheds in the Salish Sea Bioregion layer from the [Salish Sea Atlas Data](https://salish-sea-atlas-data-wwu.hub.arcgis.com/). Sample code is also given for loading a geodatabase. 

A polygon should have counts in all years to ensure that sampling is complete and consistent. Those that have incomplete time series are removed. 

```{r spatial}

#Load your .shp file saved in the Data/Sptail folder
poly <- st_read("Data/Spatial/Salish_Sea_Watersheds.shp")

#create your point layer
loc<-events %>% select(SurveyAreaIdentifier, DecimalLatitude, DecimalLongitude) %>% distinct()
xy<-st_as_sf(loc, coords = c("DecimalLongitude", "DecimalLatitude"))
st_crs(xy)<-"+proj=longlat +datum=NAD83"

#ensure the coordinate reference systems are the same
newCRS<-st_crs(poly) #get the CRS of the poly data
xy<-st_transform(xy, newCRS) #transform 
Grid <- poly %>% st_filter(xy, .pred = st_intersects)
Grid$Name[15]<-"Central Vancover Island" #rename one of the polygons as it is duplicated 
#Add SurveyAreaIdentifier to polygon name
loc.xy<- st_join(Grid, xy)

#Visualize your points and polygons before proceeding
#Load basemap for the Data library
map<- st_read("Data/Spatial/Salish_Sea_Water_Polygon.shp")
map_sf <- st_transform(map, st_crs(newCRS))

ggplot() +
  geom_sf(data = Grid, aes(fill = Name), color = "black") +
  geom_sf(data = map_sf, size = 0.2) +
  geom_sf(data = xy, color = "black", size = 1) +
  theme_minimal()

grid<-loc.xy %>% 
  st_drop_geometry() %>% 
  select(SurveyAreaIdentifier, Name) %>% #select the name and/or ID associated with your polygon. 
  distinct() %>% 
  #create the alpha index for the analysis 
  mutate(alpha_i = as.integer(factor(Name)))

#joint to your events layer
events<-left_join(events, grid, by="SurveyAreaIdentifier") %>% st_drop_geometry()
#remove the areas that fall outside the polygons
events<-events %>% drop_na(Name)

```


## 4.2 Set Analysis Parameters {#4.2iCAR}

Here the user has several customization options.

-   Select the study area.

-   For a species-specific analysis, select the species you wish to analyse.

-   Set the minimum data requirements.

-   Select the distributional family.

-   Set random and spatail priors, or retain the defaults below, which balance flexibility with regularization, reducing over-fitting risk while maintaining spatial structure.

*Note: R is case sensitive so type your variable names carefully and as specified below*

```{r}

#To view your options of species
species<-unique(sp.data$CommonName)
#view(species)

#Create a list of species using all available species in the shared dataset.
species.list<-"ALL"

#Or you can manually select species.
#species.list <- c("American Wigeon", "Common Loon", "Large Gull") 

#Select the minimum data requirements for the analysis. The ones selected here were done following the inspection of the International data set and likely work both the National analyses. However, finer scale assessment may need to assess their suitability. 

#Here, the minimum data required across sites with at least one detection, each species needs an overall abundance per year > 10, need to be detected in > one-half of the survey years, and on > 10 survey sites. Users may choose to adjust these parameters. 

min.abundance <- 10
min.years <- (Y2-Y1)/2
nsites <- 10

#Set the distributional assumption. Here we select 'nbinomal' but this may need to adjust if there is overdispersion. 

fam<-'nbinomial'
#fam<-'zeroinflatednbinomial1'
#fam<-'poisson'

#Priors for the random effects
hyper.iid <- list(prec = list(prior = "pc.prec", param = c(1, 0.01)))

```

-   For a guild-specific analysis, select the guild you wish to analyse (i.e., migration, diet, or family), and the species will be used as a random effect in the model.

-   Select the guild and distributional family.

*You do not need to run this code chunk if doing a species-specific analysis. Default guild is set to "No".*

```{r}

#To view your options of guilds:
migration<-unique(sp.data$Migration)
#view(migration)

diet<-unique(sp.data$Diet)
#view(diet)

family<-unique(sp.data$family_name)
#view(family)

#If you wish to do a guild-specific analysis, change to "Yes" and specify the `type` as either "migration", "diet", or "family". This will override the species list above. 

guild <- "Yes"
type <-"diet"

```

## 4.3 Run the Analysis and Plot Output {#4.3iCAR}

```{r}

#Create an output file to save your results
#Give your analytically output file a unique name 
#e.g., BCCWS_Species, SalishSea_guild

name<-"SalishSea_Species"

#This is the template used for the State of Canada's Birds and is required for upload into NatureCounts
source("OutputTables2.R")

#Now we can initiate the analysis.  
source("Analysis_iCAR.R")

```

Note that the Dispersion Statistic file in the Output folder should be reviewed after the analysis. If the statistic is \> 10 you should inspect the FitPlots in the Plot directory. In this case we will want to rerun using a different distributional assumption on the counts. This can be done by manually changing the `fam` to Poission and selecting these species to be rerun.

## 4.4 Spatail Graph the Results for Visual Inspection {4.4iCAR}

```{r}

source("Graph_iCAR.R")

```

